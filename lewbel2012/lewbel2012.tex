\begin{filecontents}[force]{refs.bib}
@article{lewbel2012,
author = {Arthur Lewbel},
title = {Using Heteroscedasticity to Identify and Estimate Mismeasured and Endogenous Regressor Models},
journal = {Journal of Business \& Economic Statistics},
volume = {30},
number = {1},
pages = {67--80},
year = {2012},
publisher = {ASA Website},
doi = {10.1080/07350015.2012.643126},
URL = {https://doi.org/10.1080/07350015.2012.643126},
eprint = {https://doi.org/10.1080/07350015.2012.643126}
}

@article{rigobon2003,
    author = {Rigobon, Roberto},
    title = {Identification Through Heteroskedasticity},
    journal = {The Review of Economics and Statistics},
    volume = {85},
    number = {4},
    pages = {777-792},
    year = {2003},
    month = {11},
    issn = {0034-6535},
    doi = {10.1162/003465303772815727},
    url = {https://doi.org/10.1162/003465303772815727},
    eprint = {https://direct.mit.edu/rest/article-pdf/85/4/777/1613607/003465303772815727.pdf}
}

@article{prono2014,
author = {Prono, Todd},
title = {The Role of Conditional Heteroskedasticity in Identifying and Estimating Linear Triangular Systems, with Applications to Asset Pricing Models That Include a Mismeasured Factor},
journal = {Journal of Applied Econometrics},
volume = {29},
number = {5},
pages = {800-824},
doi = {https://doi.org/10.1002/jae.2340},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jae.2340},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/jae.2340},
year = {2014}
}

@article{klein2010estimating,
title = {Estimating a class of triangular simultaneous equations models without exclusion restrictions},
journal = {Journal of Econometrics},
volume = {154},
number = {2},
pages = {154-164},
year = {2010},
issn = {0304-4076},
doi = {https://doi.org/10.1016/j.jeconom.2009.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S0304407609001675},
author = {Roger Klein and Francis Vella},
shortauthor = {K\&V}
}

\end{filecontents}

\documentclass{article}
\usepackage{csquotes}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{geometry}
\geometry{verbose}

% This line is now correct and should be the only biblatex line
\usepackage[backend=biber, style=authoryear-comp]{biblatex}
\addbibresource{refs.bib}

\usepackage{enumitem}
\usepackage{hyperref}


\makeatletter
% ---------- shortcuts ----------
\newcommand{\E}{\mathbb{E}}
\newcommand{\cov}{\operatorname{Cov}}
\newcommand{\corr}{\operatorname{Corr}}
\newcommand{\var}{\operatorname{Var}}
\newcommand{\plim}{\operatorname*{plim}}
\newcommand{\argmin}{\operatorname*{arg\,min}}

% ---------- theorem environments ----------
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}\newtheorem{remark}{Remark}
\newtheorem{cor}{Corollary}[section]

% ---------- transpose symbol ----------
\newcommand{\T}{^{\top}}
\makeatother

\title{Heteroskedasticity-Based Identification}
\author{}
\date{}

\begin{document}

\maketitle

\section{Identification Through Heteroskedasticity}

This document summarizes the heteroskedasticity-based identification
strategy for models with endogenous regressors, as developed by \textcite{lewbel2012},
\textcite{klein2010estimating}, \textcite{rigobon2003} and \textcite{prono2014}, and proposes an
application to a time-series context. The method provides a way to
construct valid instruments from the model's data when traditional
external instruments are unavailable and heteroskedasticity is present.

\section[Lewbel (2012)]{\textcite{lewbel2012}}

\subsection{Structural Forms and Reduced-Form Residuals}

Let $(Y_{1},Y_{2})$ be an endogenous vector, $X$ a vector of exogenous
variables (including a constant).

The models we consider are:

\begin{align*}
\textbf{Triangular:}\quad & Y_{1}=X\T\beta_{1}+\gamma_{1}Y_{2}+\varepsilon_{1}, & \quad Y_{2}=X\T\beta_{2}+\varepsilon_{2},\\[3pt]
\textbf{Simultaneous:}\quad & Y_{1}=X\T\beta_{1}+\gamma_{1}Y_{2}+\varepsilon_{1}, & \quad Y_{2}=X\T\beta_{2}+\gamma_{2}Y_{1}+\varepsilon_{2}.
\end{align*}
with $\gamma_{1}\gamma_{2}\neq1$.

Projecting each $Y_{j}$ on $X$ yields \emph{reduced-form residuals}
$W_{j}\coloneqq Y_{j}-X\T(\E[XX\T])^{-1}\E[XY_{j}]$. A short calculation
gives
\[
W_{1}=\frac{\varepsilon_{1}+\gamma_{1}\varepsilon_{2}}{1-\gamma_{1}\gamma_{2}},\qquad W_{2}=\frac{\varepsilon_{2}+\gamma_{2}\varepsilon_{1}}{1-\gamma_{1}\gamma_{2}},
\]
with the triangular case obtained by setting $\gamma_{2}=0$.

\begin{remark} The algebra follows directly from solving the two-equation
system for the reduced form and collecting the error terms. \end{remark}

\subsection{Core Assumptions for Lewbel-Style Identification}

The method relies on the following key assumptions:

\begin{enumerate}[label=(LW\arabic*), ref=(LW\arabic*)]
\item \label{enu:exogeneity}\textbf{Strict exogeneity.} $\E[\varepsilon_{j}\mid X]=0$
for $j=1,2$. \\ \emph{Time-series note:} in Section \ref{sec:timeseries}
we weaken this to a martingale-difference assumption.
\item \label{enu:error_covariance}\textbf{Covariance restriction.} $\cov(Z,\varepsilon_{1}\varepsilon_{2})=0$.
This holds automatically if the errors have a common factor structure
$\varepsilon_{j}\coloneqq a_{j}u+\eta_{j}$ where the common factor
$u$ is mean independent of $Z$, i.e., $\E[u\mid Z]=0$.
\item \label{enu:het}\textbf{Instrument relevance via heteroskedasticity.}
\begin{itemize}
\itemsep2pt
\item \emph{Triangular:} $\cov(Z,\varepsilon_{2}^{2})\neq0$.
\item \emph{Simultaneous:} the $r\times2$ matrix $\Phi_{W}\coloneqq[\,\cov(Z,W_{1}^{2})\;\;\cov(Z,W_{2}^{2})\,]$
has rank 2.
\end{itemize}
\item \textbf{\label{enu:norm}Normalization (simultaneous case).} The parameter
space for $(\gamma_{1},\gamma_{2})$ precludes the observationally
equivalent pair $(1/\gamma_{2},1/\gamma_{1})$.
\end{enumerate}

\subsection{Triangular System: Closed-Form Identification and 2SLS}

The coefficient $\gamma$ has closed-form:

\begin{equation}
\gamma_{1}=\frac{\cov(Z,W_{1}W_{2})}{\cov(Z,W_{2}^{2})}.\label{eq:gamma1_id}
\end{equation}

\begin{remark}[Why \eqref{eq:gamma1_id} identifies $\gamma_{1}$]
Under \ref{enu:error_covariance} the numerator simplifies to $\cov(Z,\varepsilon_{1}\varepsilon_{2})+\gamma_{1}\cov(Z,\varepsilon_{2}^{2})=\gamma_{1}\cov(Z,\varepsilon_{2}^{2})$.
Because the denominator is non-zero by \ref{enu:het}, $\gamma_{1}$
is point identified. \end{remark}

\subsection{Feasible two-step 2SLS}

\label{subsec:2SLS}

For the triangular system:
\begin{enumerate}
\itemsep2pt
\item \textbf{Generate residuals.} Regress $Y_{2}$ on $X$ via OLS and
store the residuals $\hat{\varepsilon}_{2}\coloneqq Y_{2}-X\T\hat{\beta}_{2}^{\text{OLS}}$.
\item \textbf{Construct the heteroskedasticity-based instrument.} The generated
instrument is $IV\coloneqq(Z-\bar{Z})\hat{\varepsilon}_{2}$.
\item \textbf{First stage.} Regress the endogenous variable $Y_{2}$ on
the exogenous variables and the generated instrument, $[X,IV]$, to
obtain fitted values $\hat{Y}_{2}$.
\item \textbf{Second stage.} Regress $Y_{1}$ on $[X,\hat{Y}_{2}]$ to estimate
$(\beta_{1},\gamma_{1})$.
\end{enumerate}

\paragraph{Weak Instruments}

Weak-instrument concerns apply because the instrument is generated.
Report the first-stage F-statistic on $IV$ and, where necessary,
use weak-IV-robust inference. Standard errors should account for the
first-stage estimation step, typically via GMM or bootstrap.

\subsection{GMM Moment Conditions}

The identification strategy can be expressed more generally using
GMM. The core idea is to form moment conditions that are zero at the
true parameter values $\theta$.

\subsection{Triangular system}

The parameter vector is $\theta\coloneqq\bigl(\beta_{1}\T,\gamma_{1},\beta_{2}\T\bigr)\T$.
The moment vector is formed by multiplying instruments by the model's
structural errors, which are defined as $\varepsilon_{1}(\theta)\coloneqq Y_{1}-X\T\beta_{1}-Y_{2}\gamma_{1}$
and $\varepsilon_{2}(\theta)\coloneqq Y_{2}-X\T\beta_{2}$.
\begin{equation}
Q_{\text{TRI}}(\theta)\coloneqq\begin{pmatrix}X\cdot\varepsilon_{1}(\theta)\\[3pt]
X\cdot\varepsilon_{2}(\theta)\\[3pt]
(Z-\bar{Z})\cdot\varepsilon_{1}(\theta)\cdot\varepsilon_{2}(\theta)
\end{pmatrix}.\label{eq:moment_tri}
\end{equation}
The instruments are constructed directly from the exogenous data:
\begin{itemize}
\itemsep0pt
\item For the two mean equations, the instruments are the exogenous variables
$X$.
\item For the covariance restriction, the instrument is the de-meaned heteroskedasticity
driver $Z-\bar{Z}$.
\end{itemize}
Since the errors are functions of data and parameters, the entire
moment vector is observable for any candidate $\theta$.

\subsection{Simultaneous system}\label{subsec:sys}

The parameter vector is $\theta\coloneqq(\beta_{1}\T,\gamma_{1},\beta_{2}\T,\gamma_{2})\T$.
The structural errors are now $\varepsilon_{1}(\theta)\coloneqq Y_{1}-X\T\beta_{1}-Y_{2}\gamma_{1}$
and $\varepsilon_{2}(\theta)\coloneqq Y_{2}-X\T\beta_{2}-Y_{1}\gamma_{2}$.
\begin{equation}
Q_{\text{SIM}}(\theta)\coloneqq\begin{pmatrix}X\cdot\varepsilon_{1}(\theta)\\[3pt]
X\cdot\varepsilon_{2}(\theta)\\[3pt]
(Z-\bar{Z})\cdot\varepsilon_{1}(\theta)\cdot\varepsilon_{2}(\theta)
\end{pmatrix}.\label{eq:moment_sim}
\end{equation}
The instruments are again constructed from exogenous data: $X$ for
the mean equations and $Z-\bar{Z}$ for the covariance restriction.

\subsection{GMM Estimation}
Estimation proceeds by finding the parameter vector $\hat{\theta}$ that minimizes
the sample analog of the moment conditions, $\bar{Q}(\theta)\T W\bar{Q}(\theta)$,
where $W$ is a weighting matrix.

Note that in the case of a simultaneous system, Assumption \ref{enu:het} requires $Z$ to
contain at least two elements. Some times we can use a constant as
an instrument (and include it in $Z-\bar{Z}$).
\begin{cor}
\label{cor:const_Z}Let Assumptions \ref{enu:exogeneity}, \ref{enu:error_covariance},
\ref{enu:het}, and \ref{enu:norm} hold in the simultaneous equation
model, replacing $\cov(Z,\varepsilon_{1}\varepsilon_{2})$
in Assumption \ref{enu:error_covariance} with $\E((Z-\bar{Z})\varepsilon_{1}\varepsilon_{2})$
and replacing $\cov(Z,W_{j}^{2})$ with $\E((Z-\bar{Z})W_{j}^{2})$
in Assumption \ref{enu:het}, for $j=1,2$. Then, all the parameters
are identified.
\end{cor}

Corollary \ref{cor:const_Z} can be used when $\E[\varepsilon_{1}\varepsilon_{2}]=0$.

\subsection{Set Identification Under a Relaxed Covariance Restriction}

When assumption \ref{enu:error_covariance} is weakened to allow for
a small correlation, $|\corr(Z,\varepsilon_{1}\varepsilon_{2})|\le\tau|\corr(Z,\varepsilon_{2}^{2})|,\;\tau\in[0,1)$,
the parameter $\gamma_{1}$ in the triangular model is set-identified
rather than point-identified.

\begin{theorem}[Bounds for \(\gamma_1\) with \(\tau>0\)] \label{thm:bounds}
$\gamma_{1}$ is contained in the closed interval whose endpoints
are the (real) roots of the quadratic equation in $\gamma_{1}$:
\[
\frac{\cov(Z,W_{1}W_{2})^{2}}{\cov(Z,W_{2}^{2})^{2}}-\frac{\var(W_{1}W_{2})}{\var(W_{2}^{2})}\tau^{2}+2\!\left(\frac{\cov(W_{1}W_{2},W_{2}^{2})}{\var(W_{2}^{2})}\tau^{2}-\frac{\cov(Z,W_{1}W_{2})}{\cov(Z,W_{2}^{2})}\right)\!\gamma_{1}+(1-\tau^{2})\gamma_{1}^{2}=0.
\]
\end{theorem} The interval collapses to the point estimate from \eqref{eq:gamma1_id}
when $\tau=0$ and widens as $\tau\to1$.

\paragraph{Identification of other parameters.}

The remaining parameters are identified conditional on a value of
$\gamma_{1}$ from its identified set.
\begin{itemize}
\itemsep0pt
\item The parameter $\beta_{2}$ is always point-identified by OLS: $\hat{\beta}_{2}\coloneqq(\E[X\T X])^{-1}\E[X\T Y_{2}]$.
\item For each value $\gamma_{1,k}$ in the identified interval for $\gamma_{1}$,
there is a corresponding identified value for $\beta_{1}$, given
by $\beta_{1,k}\coloneqq(\E[X\T X])^{-1}\E[X\T(Y_{1}-Y_{2}\gamma_{1,k})]$.
\end{itemize}
The result is an identified set of parameter pairs $(\beta_{1},\gamma_{1})$
corresponding to the interval for $\gamma_{1}$.

This set-identification cannot be used in the simultaneous system.

\section[Klein and Vella (2010)]{\textcite{klein2010estimating}}

\subsection{Semiparametric Control Function Approach}

An alternative to the IV/GMM framework for the triangular system is the semiparametric control function approach of \textcite{klein2010estimating}. This method addresses endogeneity by directly augmenting the structural equation with a non-constant control term.

\subsection{The Model and General Control Function}

The starting point is a general statistical decomposition of the first structural error via a linear projection onto the second error, conditional on the exogenous variables:
\[
\varepsilon_1 = A(X)\varepsilon_2 + \eta_1, \qquad \text{where} \quad \E[\eta_1 | X, \varepsilon_2] = 0.
\]
This decomposition holds by defining $A(X)$ as the coefficient from a conditional linear projection, given by:
\[
A(X) \coloneqq \frac{\cov(\varepsilon_1, \varepsilon_2 \mid X)}{\var(\varepsilon_2 \mid X)}.
\]
Substituting this into the primary structural equation yields the augmented regression model:
\begin{equation}
Y_1 = X\T\beta_1 + \gamma_1 Y_2 + A(X)\varepsilon_2 + \eta_1. \label{eq:cf_model}
\end{equation}
Identification hinges on giving the generally intractable function $A(X)$ an estimable structure.

\subsection{Assumptions for Identification}
The key assumptions which provide this structure are:
\begin{enumerate}[label=(KV\arabic*), ref=(KV\arabic*)]
    \item \label{enu:kv_exogeneity} \textbf{Exogeneity.} $\E[\varepsilon_j | X] = 0$ for $j=1,2$.
    \item \label{enu:kv_corr} \textbf{Constant Conditional Correlation.} The correlation between the structural errors is constant conditional on $X$: $\corr(\varepsilon_1, \varepsilon_2 | X) = \rho_0$.
    \item \label{enu:kv_het} \textbf{Heteroskedasticity and Variation.} The conditional variances are non-constant functions of $X$, denoted $\var(\varepsilon_j|X) = S_j^2(X)$. Crucially, the ratio of the conditional standard deviations, $S_1(X)/S_2(X)$, is not a constant.
\end{enumerate}

\subsection{Identification via Control Function}
The \textcite{klein2010estimating} assumptions transform the inestimable general form of $A(X)$ into a specific, identifiable structure. The derivation proceeds as follows:
\begin{align*}
A(X) &= \frac{\cov(\varepsilon_1, \varepsilon_2 \mid X)}{\var(\varepsilon_2 \mid X)} &&\text{(General Definition)} \\
&= \frac{\corr(\varepsilon_1, \varepsilon_2 \mid X) S_1(X) S_2(X)}{S_2^2(X)} &&\text{(Definition of Correlation)} \\
&= \frac{\rho_0 S_1(X) S_2(X)}{S_2^2(X)} &&\text{(Using Assumption \ref{enu:kv_corr})} \\
&= \rho_0 \frac{S_1(X)}{S_2(X)} &&\text{(Identified Form)}
\end{align*}
While the original form is inestimable due to the unknown conditional covariance function, this final form depends only on the parameter $\rho_0$ and the conditional standard deviation functions, which can be estimated nonparametrically. Assumption \ref{enu:kv_het} is crucial as it ensures this ratio is not constant. If the ratio were a constant, say~$c$, the model would collapse into a simple linear form \(Y_1 = X\T\tilde{\beta}_1 + Y_2\tilde{\gamma}_1 + \eta_1\), where an estimator could only identify the two composite parameters $\tilde{\beta}_1$ and $\tilde{\gamma}_1$, leaving the three structural parameters $(\beta_1, \gamma_1, \rho_0)$ unidentified from the two equations:
\begin{align*}
\hat{\tilde{\beta}}_1 &= \beta_1 - \rho_0 c \beta_2 \\
\hat{\tilde{\gamma}}_1 &= \gamma_1 + \rho_0 c
\end{align*}

\subsection{Estimation Strategy}
With the identified control function, the estimable regression model is:
\[
Y_1 = X\T\beta_1 + \gamma_1 Y_2 + \rho_0 \frac{S_1(X)}{S_2(X)}\varepsilon_2 + \eta_1.
\]
The parameters $(\beta_1, \gamma_1, \rho_0)$ and the unknown variance functions are estimated jointly via a multi-step Semiparametric Least Squares (SLS) procedure.
\begin{enumerate}
    \itemsep2pt
    \item \textbf{First-step residual.} Estimate the second structural equation $Y_2 = X\T\beta_2 + \varepsilon_2$ by OLS to obtain consistent residuals $\hat{\varepsilon}_2$.
    \item \textbf{Second-error variance.} Estimate the conditional variance function $S_2^2(X) = \var(\varepsilon_2|X)$ by nonparametrically regressing the squared residuals $\hat{\varepsilon}_2^2$ on $X$, for instance using kernel regression. This yields the estimator $\hat{S}_2(X)$.
    \item \textbf{Main equation SLS.} The primary parameters $(\beta_1, \gamma_1, \rho_0)$ are estimated by minimizing the sum of squared residuals of the main equation. This is a nested procedure where for each candidate parameter vector $(\beta_{1,k}, \gamma_{1,k}, \rho_{0,k})$:
    \begin{enumerate}[label=(\alph*)]
        \itemsep1pt
        \item The structural error $\hat{\varepsilon}_{1,k} = Y_1 - X\T\beta_{1,k} - Y_2\gamma_{1,k}$ is computed.
        \item The variance function $\hat{S}_{1,k}(X)$ is estimated by nonparametrically regressing $\hat{\varepsilon}_{1,k}^2$ on $X$.
        \item The objective function $\sum_{i=1}^N \left( Y_{1i} - X_i\T\beta_{1,k} - Y_{2i}\gamma_{1,k} - \rho_{0,k}\frac{\hat{S}_{1,k}(X_i)}{\hat{S}_2(X_i)}\hat{\varepsilon}_{2i} \right)^2$ is evaluated.
    \end{enumerate}
    The final parameter estimates are those which minimize this objective function.
\end{enumerate}

\subsection{Fully Parametric Estimation}
The most direct simplification replaces the unknown variance functions $S_j(X)$ with specific parametric forms, converting the semiparametric problem into a standard parametric one. A common specification that ensures positivity is the exponential model:
\[
S_j^2(X) = \var(\varepsilon_j|X) = \exp(X\T\delta_j), \quad \text{for } j=1,2.
\]
The full parameter vector for the triangular system is now finite-dimensional: $\theta \coloneqq (\beta_1\T, \gamma_1, \beta_2\T, \rho_0, \delta_1\T, \delta_2\T)\T$. Estimation can proceed via Maximum Likelihood or GMM.

\paragraph{Maximum Likelihood Estimation (MLE).}
This approach requires a full distributional assumption for the structural errors. Assuming $(\varepsilon_1, \varepsilon_2)$ are conditionally bivariate normal given $X$, the distribution is:
\[
\begin{pmatrix} \varepsilon_1 \\ \varepsilon_2 \end{pmatrix} \mid X \sim \mathcal{N} \left( \begin{pmatrix} 0 \\ 0 \end{pmatrix}, \Sigma(X; \theta) \right),
\]
where the conditional covariance matrix $\Sigma(X; \theta)$ is a function of the parameters:
\[
\Sigma(X; \theta) = \begin{pmatrix}
\exp(X\T\delta_1) & \rho_0 \exp(\frac{1}{2}X\T(\delta_1+\delta_2)) \\
\rho_0 \exp(\frac{1}{2}X\T(\delta_1+\delta_2)) & \exp(X\T\delta_2)
\end{pmatrix}.
\]
The structural errors are functions of the mean parameters: $\varepsilon_1(\theta) = Y_1 - X\T\beta_1 - Y_2\gamma_1$ and $\varepsilon_2(\theta) = Y_2 - X\T\beta_2$. The MLE estimator $\hat{\theta}_{\text{MLE}}$ is the value of $\theta$ that maximizes the log-likelihood function, $\mathcal{L}(\theta) = \sum_{i=1}^N \log f(\varepsilon_{1i}(\theta), \varepsilon_{2i}(\theta) \mid X_i; \theta)$, where $f(\cdot)$ is the bivariate normal PDF.

\paragraph{Generalized Method of Moments (GMM).}
GMM provides a more robust alternative that does not require a full distributional assumption. A set of moment conditions sufficient to identify $\theta$ is given by $\E[Q(\theta)]=0$, where:
\[
Q(\theta) \coloneqq \begin{pmatrix}
X \cdot \varepsilon_1(\theta) \\
X \cdot \varepsilon_2(\theta) \\
X \cdot (\varepsilon_1(\theta)^2 - \exp(X\T\delta_1)) \\
X \cdot (\varepsilon_2(\theta)^2 - \exp(X\T\delta_2)) \\
X \cdot (\varepsilon_1(\theta)\varepsilon_2(\theta) - \rho_0 \exp(\frac{1}{2}X\T(\delta_1+\delta_2)))
\end{pmatrix}.
\]
The first two sets of moments identify the mean parameters ($\beta_1, \gamma_1, \beta_2$). The next two sets use the assumed variance structure to identify the variance parameters ($\delta_1, \delta_2$), and the final set identifies the correlation parameter $\rho_0$. The GMM estimator $\hat{\theta}_{\text{GMM}}$ minimizes the standard quadratic form $\bar{Q}(\theta)\T W \bar{Q}(\theta)$ for a given weighting matrix $W$.

\section{Two Time-Series Examples}

The core idea can be adapted to other contexts by properly defining
the heteroskedasticity-generating variable $Z$.

\subsection[Prono (2014)]{\textcite{prono2014}}

\paragraph{Model.}

In a time-series setting, the structural model is a triangular system:
\begin{align*}
Y_{1t} & =X_{t}\T\beta_{1}+\gamma_{1}Y_{2t}+\varepsilon_{1t}\\
Y_{2t} & =X_{t}\T\beta_{2}+\varepsilon_{2t}
\end{align*}
The key insight is that the error variance may be time-varying and
predictable. \textcite{prono2014} assumes $\varepsilon_{2t}$ follows
a GARCH process, where its conditional variance is a function of past
errors and variances:
\[
\var(\varepsilon_{2t}\mid\mathcal{F}_{t-1})\coloneqq\sigma_{2t}^{2}=\omega+\alpha\varepsilon_{2,t-1}^{2}+\beta\sigma_{2,t-1}^{2}.
\]


\paragraph{Procedure.}

The fitted conditional variance from the GARCH model serves as the
heteroskedasticity driver.
\begin{enumerate}
\itemsep2pt
\item Estimate the second equation by OLS to get residuals $\hat{\varepsilon}_{2t}\coloneqq Y_{2t}-X_{t}\T\hat{\beta}_{2}$.
\item Fit a GARCH(1,1) model to the residuals $\hat{\varepsilon}_{2t}$
to obtain the series of fitted conditional variances, $\hat{\sigma}_{2t}^{2}$.
\item This fitted variance is the heteroskedasticity driver: set $Z_{t}\coloneqq\hat{\sigma}_{2t}^{2}$.
\item Construct the generated instrument: $IV_{t}\coloneqq(Z_{t}-\bar{Z})\hat{\varepsilon}_{2t}$.
\item Proceed with 2SLS as in Section \ref{subsec:2SLS}, using $[X_{t},IV_{t}]$
as instruments for $Y_{2t}$ in the first structural equation. Use
HAC-robust standard errors.
\end{enumerate}

\subsection[Rigobon (2003)]{\textcite{rigobon2003}}

\label{sec:rigobon_application}
\paragraph{Model Framework.}
The core idea of \textcite{rigobon2003} is that identification can be achieved if the error variances differ across observable, discrete regimes, $s \in \{1, \dots, S\}$ (e.g., pre- and post-policy change, or high- vs. low-volatility periods). The structural parameters of the model are assumed to be constant across these regimes. The structural equations are:
\begin{align*}
Y_{1} & =X\T\beta_{1}+\gamma_{1}Y_{2}+\varepsilon_{1}\\
Y_{2} & =X\T\beta_{2}+\gamma_{2}Y_{1}+\varepsilon_{2}
\end{align*}
The key assumption is that the variance-covariance matrix of the structural errors, $\Sigma_{\varepsilon}$, is different in at least two regimes. Let $\Sigma_{\varepsilon, s}$ denote this matrix in regime $s$.
\[
\Sigma_{\varepsilon, s} \coloneqq \begin{pmatrix} \sigma_{1,s}^2 & \sigma_{12,s} \\ \sigma_{12,s} & \sigma_{2,s}^2 \end{pmatrix}, \qquad \text{with } \Sigma_{\varepsilon, s} \neq \Sigma_{\varepsilon, s'} \text{ for some } s \neq s'.
\]
This regime-based heteroskedasticity can be exploited using either the Lewbel or Klein-Vella identification strategy, depending on further assumptions about the error structure.

\subsubsection{Lewbel-Style IV Procedure}
\paragraph{Assumptions.}
This approach applies to the simultaneous system. It relies on the core Lewbel assumptions, specialized to the regime context. The key identifying restrictions are:
\begin{enumerate}
    \itemsep1pt
    \item \textbf{Covariance Restriction:} The structural error \emph{covariance} is constant across regimes: $\sigma_{12,s} = \sigma_{12}$ for all $s$.
    \item \textbf{Instrument Relevance:} At least one structural error \emph{variance} is not constant across regimes: $\sigma_{j,s}^2 \neq \sigma_{j,s'}^2$ for some $j, s, s'$.
\end{enumerate}
Let $D_s$ be a dummy variable for regime $s$. The instrument vector $Z$ is formed by the set of centered dummies, $Z \coloneqq [D_1 - p_1, \dots, D_{S-1}-p_{S-1}]\T$, where $p_s$ is the population proportion in regime $s$. Under these conditions, the Lewbel assumptions \ref{enu:error_covariance} and \ref{enu:het} hold. Specifically, $\cov(Z, \varepsilon_1\varepsilon_2) = 0$ because both $Z$ and $\varepsilon_1\varepsilon_2$ are functions of the regime, but $\varepsilon_1\varepsilon_2$ has a constant mean across regimes while $Z$ does not.

\paragraph{Procedure.}
The regime indicators are used to generate the instrument. For the triangular case ($\gamma_2 = 0$):
\begin{enumerate}
\itemsep2pt
\item \textbf{Generate residuals.} Regress $Y_{2}$ on $X$ by OLS to get residuals $\hat{\varepsilon}_{2}$.
\item \textbf{Construct instruments.} The heteroskedasticity drivers are the centered dummy variables, $Z_{s}\coloneqq D_{s}-\bar{D}_{s}$. The generated instruments are $IV_{s}\coloneqq Z_{s}\hat{\varepsilon}_{2}$.
\item \textbf{Proceed with 2SLS,} using $[X,IV_{1},\dots,IV_{S-1}]$ as instruments for $Y_{2}$.
\end{enumerate}

\subsubsection{Klein \& Vella-Style Control Function Procedure}
\paragraph{Assumptions.}
This approach applies to the triangular system ($\gamma_2=0$). It relies on the core K\&V assumptions, specialized to the regime context.
\begin{enumerate}
    \itemsep1pt
    \item \textbf{Constant Conditional Correlation:} The structural error \emph{correlation} is constant across regimes: $\corr(\varepsilon_1, \varepsilon_2 \mid s) = \rho_0$ for all $s$.
    \item \textbf{Heteroskedasticity and Variation:} The structural error \emph{variances} are not constant across regimes. Crucially for identification, the ratio of the standard deviations, $\sigma_{1,s}/\sigma_{2,s}$, must not be constant for all $s$.
\end{enumerate}

\paragraph{Procedure.}
The regime indicators are used to construct a piecewise control function. The simplest case is where the conditional variances are constant within each regime, i.e., $\var(\varepsilon_j \mid s) = \sigma_{js}^2$.
\begin{enumerate}
    \itemsep2pt
    \item \textbf{Estimate second-equation residuals.} Regress $Y_2$ on $X$ to get residuals $\hat{\varepsilon}_2$.
    \item \textbf{Estimate regime-specific variances.} For each regime $s$, compute the sample variance of the residuals, $\hat{\sigma}_{2s}^2 = \frac{1}{N_s}\sum_{i \in s} \hat{\varepsilon}_{2i}^2$. For any candidate $(\beta_{1k}, \gamma_{1k})$, compute $\hat{\varepsilon}_{1k}$ and its regime-specific variances $\hat{\sigma}_{1ks}^2$.
    \item \textbf{Estimate via nonlinear least squares (NLS).} The main equation is specified with an interacted control function:
    \[
    Y_1 = X\T\beta_1 + \gamma_1 Y_2 + \rho_0 \sum_{s=1}^S D_s \! \left( \frac{\sigma_{1s}}{\sigma_{2s}} \hat{\varepsilon}_2 \right) + \eta_1
    \]
    The parameters $(\beta_1, \gamma_1, \rho_0)$ and the variance ratios $(\sigma_{1s}/\sigma_{2s})$ for $s=1,\dots,S$ are estimated jointly via NLS.
\end{enumerate}

\subsubsection{Comparison of Approaches}
The Lewbel and K\&V approaches use the same observable phenomenon—a shift in the error variance structure across regimes—but rely on different, non-nested assumptions to achieve identification.
\begin{itemize}
\item \textbf{Core Assumption:} Lewbel requires the \emph{covariance} of the structural errors to be constant across regimes. K\&V requires the \emph{correlation} to be constant. If both variances change across regimes, these two assumptions are mutually exclusive.
\item \textbf{Applicability:} The Lewbel approach is more general as it applies to simultaneous systems. The K\&V control function approach, as formulated, is restricted to triangular systems.
\item \textbf{Estimation:} Lewbel's method leads to a standard linear IV (2SLS) procedure. K\&V's method requires a more complex nonlinear least squares estimation to handle the variance ratios and correlation parameter.
\end{itemize}
The choice between the two depends on which assumption about the stability of the error structure—constant covariance or constant correlation—is more plausible in a given economic application.

\section{Time-Series Variant with Log-Linear Conditional Variances}

\label{sec:timeseries}

\paragraph{Model.}

The structural model is a simultaneous system:
\begin{align*}
Y_{1t} & =X_{t}\T\beta_{1}+\gamma_{1}Y_{2t}+\varepsilon_{1t}\\
Y_{2t} & =X_{t}\T\beta_{2}+\gamma_{2}Y_{1t}+\varepsilon_{2t}
\end{align*}
The key assumption is that the conditional variances are an explicit
log-linear function of the exogenous variables $X_{t}$:
\[
\log\sigma_{jt}^{2}\coloneqq X_{t}\T\delta_{j},\quad\text{where}\quad\varepsilon_{jt}\mid\mathcal{F}_{t-1}\sim(0,\sigma_{jt}^{2})\quad\text{for }j=1,2.
\]
and $\mathcal{F}_{t-1}$ denotes time $(t-1)$-information. Since
$(\delta_{1},\delta_{2})$ are assumed non-zero, $X_{t}$ is correlated
with $\varepsilon_{jt}^{2}$, satisfying the instrument relevance
condition \ref{enu:het}. The heteroskedasticity driver is defined
as the centered exogenous variables, $Z_{t}\coloneqq X_{t}-\E[X_{t}]$.

\subsection{Moment vector}

The full set of parameters is $\theta\coloneqq(\beta_{1}\T,\beta_{2}\T,\gamma_{1},\gamma_{2},\delta_{1}\T,\delta_{2}\T)\T$.
The moment conditions implied by the model are $\E[Q_{t}(\theta)]=0$,
where:
\[
Q_{t}(\theta)\coloneqq\begin{pmatrix}
X_{t} \cdot \varepsilon_{1t}(\theta)\\[2pt]
X_{t} \cdot \varepsilon_{2t}(\theta)\\[2pt]
Z_{t} \cdot \varepsilon_{1t}(\theta)\varepsilon_{2t}(\theta)\\[2pt]
Z_{t} \cdot   (\varepsilon_{1t}(\theta)^{2}-e^{X_{t}\T\delta_{1}})\\[2pt]
Z_{t} \cdot   (\varepsilon_{2t}(\theta)^{2}-e^{X_{t}\T\delta_{2}})
\end{pmatrix}.
\]


\paragraph{Instruments as Functions of Observables.}

The instruments are derived from the exogenous variables $X_{t}$.
The terms inside the expectation are functions of these instruments
and the structural errors (e.g., $\varepsilon_{1t}(\theta)\coloneqq Y_{1t}-X_{t}\T\beta_{1}-Y_{2t}\gamma_{1}$),
which are themselves functions of the observable data and the parameter
vector $\theta$.
\begin{itemize}
\item For the first two mean equations, the instruments are $X_{t}$.
\item For the error product and variance specification moments, the instrument
is $Z_{t}\coloneqq X_{t}-\E[X_{t}]$, estimated in-sample as $X_{t}-\bar{X}$.
\end{itemize}
Therefore, the sample average of $Q_{t}(\theta)$ is a computable
criterion function for any candidate parameter values. As in Section \ref{subsec:sys}, $Z_t$
must have at least 2 entries (including perhaps a constant, if Corollary \ref{cor:const_Z} applies).

\section{Other Notes}
\begin{itemize}
\itemsep2pt
\item \textbf{Instrument relevance.} Report the first-stage $F$-statistic
on the generated instrument(s); if $F<10$, standard inference is
unreliable, and weak-IV-robust tests should be used.
\item \textbf{Instrument validity.} If there are more heteroskedasticity
drivers $Z$ than needed for identification (i.e., the model is overidentified),
a Hansen $J$-test of overidentifying restrictions can be used to
test the validity of the moment conditions.
\item \textbf{Endogeneity of $Y_{2}$.} The endogeneity of $Y_{2}$ can
be tested using a difference-in-Hansen test (C-statistic) or a Hausman-style
test comparing the OLS and 2SLS estimates of $\gamma_{1}$.
\item \textbf{Heteroskedasticity of $\varepsilon_{2}$.} The crucial assumption
\ref{enu:het} can be checked with a Breusch--Pagan or White test
for heteroskedasticity, by regressing the squared residuals $\hat{\varepsilon}_{2}^{2}$
on the proposed driver(s) $Z$. A significant relationship provides
evidence for instrument relevance.
\end{itemize}

\printbibliography

\end{document}
